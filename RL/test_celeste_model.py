import os
import subprocess
import sys
sys.path.append(os.getcwd())
import numpy as np
import gymnasium as gym
from stable_baselines3 import PPO,DQN

# æ›¿æ¢ä¸ºä½ çš„å®é™…æ¨¡å—è·¯å¾„
from RL.celeste_env import ACTIONS, CelesteGymEnv  # ğŸ‘ˆ ä¿®æ”¹è¿™é‡Œï¼

def test_model(
    model_path: str = "./models/celeste_ppo/best/best_model",
    goal=(64.0, 32.0),
    render_mode="human",      # å¯é€‰: "human"ï¼ˆæ‰“å°çŠ¶æ€ï¼‰ã€"rgb_array"ï¼ˆè¿”å›å›¾åƒï¼‰ã€Noneï¼ˆé™é»˜ï¼‰
    n_episodes=5,
    deterministic=True,
    level=0,
    custom_room=None
):
    """
    åŠ è½½æ¨¡å‹å¹¶åœ¨ç¯å¢ƒä¸­æµ‹è¯•ã€‚
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„ï¼ˆä¸å¸¦ .zipï¼‰
        goal: ç›®æ ‡ä½ç½®
        render_mode: æ¸²æŸ“æ¨¡å¼
        n_episodes: æµ‹è¯•è½®æ•°
        deterministic: æ˜¯å¦ä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥
    """
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    if not os.path.exists(model_path + ".zip"):
        raise FileNotFoundError(f"Model not found at {model_path}.zip")
    
    model = PPO.load(model_path)
    print(f"âœ… Loaded model from {model_path}")

    # åˆ›å»ºç¯å¢ƒ
    env = CelesteGymEnv(goal=goal, render_mode=render_mode,level=level,randomize_start_position=False,custom_room=custom_room)
    
    success_count = 0
    episode_rewards = []

    for ep in range(n_episodes):
        obs, _ = env.reset()
        total_reward = 0.0
        step = 0
        done = False

        print(f"\n--- Episode {ep + 1} ---")
        encoded_actions = []
        while not done:
            action, _ = model.predict(obs, deterministic=deterministic)
            l, r, u, d, z, x = ACTIONS.get(int(action), (False, False, False, False, False, False))

            # ç¼–ç ä¸ºæ•´æ•°
            encoded = l * 1 + r * 2 + u * 4 + d * 8 + z * 16 + x * 32
            encoded_actions.append(encoded)
            obs, reward, terminated, truncated, info = env.step(action)
            total_reward += reward
            step += 1

            # å¯é€‰ï¼šå®æ—¶æ¸²æŸ“ï¼ˆå¦‚æœæ”¯æŒï¼‰
            if render_mode == "human" and step%10==0:
                env.render()  # æ³¨æ„ï¼šä½ å½“å‰çš„ render() åªæ˜¯ print(p8.game)

            done = terminated or truncated

            # é˜²æ­¢æ— é™å¾ªç¯ï¼ˆå®‰å…¨ä¸Šé™ï¼‰
            if step > 1000:
                print("âš ï¸ Episode exceeded 1000 steps, forcing termination.")
                break

        episode_rewards.append(total_reward)
        success = info.get("success", False)
        if success:
            success_count += 1
            #subprocess.run(['love','CelesteTAS', 'celeste.p8', '-level', f'{level+1}','-tas', f'[]{','.join(str(a) for a in encoded_actions)}'], shell=True, capture_output=True, text=True)

        print(f"Episode {ep + 1}: Reward = {total_reward:.2f}, Steps = {step}, Success = {success} last pos x: {info['player_x']} y: {info['player_y']}")

    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    avg_reward = np.mean(episode_rewards)
    success_rate = success_count / n_episodes
    print("\n" + "="*50)
    print(f"ğŸ“Š Test Summary over {n_episodes} episodes:")
    print(f"   Average Reward: {avg_reward:.2f}")
    print(f"   Success Rate:   {success_rate * 100:.1f}% ({success_count}/{n_episodes})")
    print("="*50)

if __name__ == "__main__":
    # é…ç½®æµ‹è¯•å‚æ•°
    MODEL_PATH = "models/celeste_ppo/best/best_model"
    #MODEL_PATH = 'RL/finished_models/ppo/level4/best_model'
    GOAL = (108, -1.0) # ä¸è®­ç»ƒæ—¶ä¸€è‡´
    LEVEL = 0
    CUSTOM_ROOM=None
    test_model(
        model_path=MODEL_PATH,
        goal=GOAL,
        render_mode="human",   # æ”¹ä¸º None å¯é™é»˜æµ‹è¯•
        n_episodes=1,
        deterministic=True,
        level=LEVEL,
        custom_room=CUSTOM_ROOM
    )